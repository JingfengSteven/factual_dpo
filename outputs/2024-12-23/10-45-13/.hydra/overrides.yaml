- model=llama3-8b-instruct
- datasets=[custom_dataset]
- loss=dpo
- loss.beta=0.1
- model.archive=/dev/shm/luokaiwei/luokaiwei/anthropic_dpo_pythia28_2024-12-19_14-10-10_974391/LATEST/policy.pt
- exp_name=anthropic_dpo_pythia28
- gradient_accumulation_steps=2
- trainer=FSDPTrainer
- sample_during_eval=false
- model.fsdp_policy_mp=bfloat16
