- model=llama3-8b-instruct
- datasets=[custom_dataset]
- loss=dpo
- loss.beta=0.1
- gradient_accumulation_steps=2
- trainer=FSDPTrainer
- sample_during_eval=false
- model.fsdp_policy_mp=bfloat16
